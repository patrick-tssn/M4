Traceback (most recent call last):
  File "/scratch/wangyuxuan1/.conda/envs/longva/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/scratch/wangyuxuan1/.conda/envs/longva/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/scratch/nlp/patrick/codes/OminousLLM/intersuit/longva/eval/model_videoqa_mc.py", line 233, in <module>
    run_inference(args)
  File "/scratch/nlp/patrick/codes/OminousLLM/intersuit/longva/eval/model_videoqa_mc.py", line 124, in run_inference
    tokenizer, model, image_processor, _ = load_pretrained_model(args.model_path, args.model_base, model_name, device_map="auto")
  File "/scratch/nlp/patrick/codes/OminousLLM/intersuit/longva/model/builder.py", line 209, in load_pretrained_model
Traceback (most recent call last):
  File "/scratch/wangyuxuan1/.conda/envs/longva/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/scratch/wangyuxuan1/.conda/envs/longva/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/scratch/nlp/patrick/codes/OminousLLM/intersuit/longva/eval/model_videoqa_mc.py", line 233, in <module>
    run_inference(args)
  File "/scratch/nlp/patrick/codes/OminousLLM/intersuit/longva/eval/model_videoqa_mc.py", line 124, in run_inference
    tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=False)
  File "/scratch/wangyuxuan1/.conda/envs/longva/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py", line 854, in from_pretrained
Traceback (most recent call last):
  File "/scratch/wangyuxuan1/.conda/envs/longva/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    tokenizer, model, image_processor, _ = load_pretrained_model(args.model_path, args.model_base, model_name, device_map="auto")
  File "/scratch/nlp/patrick/codes/OminousLLM/intersuit/longva/model/builder.py", line 209, in load_pretrained_model
    tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=False)
  File "/scratch/wangyuxuan1/.conda/envs/longva/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py", line 854, in from_pretrained
    return _run_code(code, main_globals, None,
  File "/scratch/wangyuxuan1/.conda/envs/longva/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/scratch/nlp/patrick/codes/OminousLLM/intersuit/longva/eval/model_videoqa_mc.py", line 233, in <module>
    run_inference(args)
  File "/scratch/nlp/patrick/codes/OminousLLM/intersuit/longva/eval/model_videoqa_mc.py", line 124, in run_inference
    tokenizer, model, image_processor, _ = load_pretrained_model(args.model_path, args.model_base, model_name, device_map="auto")
  File "/scratch/nlp/patrick/codes/OminousLLM/intersuit/longva/model/builder.py", line 209, in load_pretrained_model
    tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=False)
  File "/scratch/wangyuxuan1/.conda/envs/longva/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py", line 854, in from_pretrained
    config = AutoConfig.from_pretrained(
    config = AutoConfig.from_pretrained(
  File "/scratch/wangyuxuan1/.conda/envs/longva/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py", line 976, in from_pretrained
  File "/scratch/wangyuxuan1/.conda/envs/longva/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py", line 976, in from_pretrained
    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/scratch/wangyuxuan1/.conda/envs/longva/lib/python3.10/site-packages/transformers/configuration_utils.py", line 632, in get_config_dict
    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/scratch/wangyuxuan1/.conda/envs/longva/lib/python3.10/site-packages/transformers/configuration_utils.py", line 632, in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/scratch/wangyuxuan1/.conda/envs/longva/lib/python3.10/site-packages/transformers/configuration_utils.py", line 689, in _get_config_dict
  File "/scratch/wangyuxuan1/.conda/envs/longva/lib/python3.10/site-packages/transformers/configuration_utils.py", line 689, in _get_config_dict
    resolved_config_file = cached_file(
  File "/scratch/wangyuxuan1/.conda/envs/longva/lib/python3.10/site-packages/transformers/utils/hub.py", line 373, in cached_file
    resolved_config_file = cached_file(
  File "/scratch/wangyuxuan1/.conda/envs/longva/lib/python3.10/site-packages/transformers/utils/hub.py", line 373, in cached_file
    raise EnvironmentError(
    raise EnvironmentError(
OSError: checkpoints/longva7b-llavanextsub100k-qwen2-rev does not appear to have a file named config.json. Checkout 'https://huggingface.co/checkpoints/longva7b-llavanextsub100k-qwen2-rev/tree/None' for available files.
OSError: checkpoints/longva7b-llavanextsub100k-qwen2-rev does not appear to have a file named config.json. Checkout 'https://huggingface.co/checkpoints/longva7b-llavanextsub100k-qwen2-rev/tree/None' for available files.
    config = AutoConfig.from_pretrained(
  File "/scratch/wangyuxuan1/.conda/envs/longva/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py", line 976, in from_pretrained
    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/scratch/wangyuxuan1/.conda/envs/longva/lib/python3.10/site-packages/transformers/configuration_utils.py", line 632, in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/scratch/wangyuxuan1/.conda/envs/longva/lib/python3.10/site-packages/transformers/configuration_utils.py", line 689, in _get_config_dict
    resolved_config_file = cached_file(
  File "/scratch/wangyuxuan1/.conda/envs/longva/lib/python3.10/site-packages/transformers/utils/hub.py", line 373, in cached_file
    raise EnvironmentError(
OSError: checkpoints/longva7b-llavanextsub100k-qwen2-rev does not appear to have a file named config.json. Checkout 'https://huggingface.co/checkpoints/longva7b-llavanextsub100k-qwen2-rev/tree/None' for available files.
Traceback (most recent call last):
  File "/scratch/wangyuxuan1/.conda/envs/longva/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/scratch/wangyuxuan1/.conda/envs/longva/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/scratch/nlp/patrick/codes/OminousLLM/intersuit/longva/eval/model_videoqa_mc.py", line 233, in <module>
    run_inference(args)
  File "/scratch/nlp/patrick/codes/OminousLLM/intersuit/longva/eval/model_videoqa_mc.py", line 124, in run_inference
    tokenizer, model, image_processor, _ = load_pretrained_model(args.model_path, args.model_base, model_name, device_map="auto")
  File "/scratch/nlp/patrick/codes/OminousLLM/intersuit/longva/model/builder.py", line 209, in load_pretrained_model
    tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=False)
  File "/scratch/wangyuxuan1/.conda/envs/longva/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py", line 854, in from_pretrained
    config = AutoConfig.from_pretrained(
  File "/scratch/wangyuxuan1/.conda/envs/longva/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py", line 976, in from_pretrained
    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/scratch/wangyuxuan1/.conda/envs/longva/lib/python3.10/site-packages/transformers/configuration_utils.py", line 632, in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/scratch/wangyuxuan1/.conda/envs/longva/lib/python3.10/site-packages/transformers/configuration_utils.py", line 689, in _get_config_dict
    resolved_config_file = cached_file(
  File "/scratch/wangyuxuan1/.conda/envs/longva/lib/python3.10/site-packages/transformers/utils/hub.py", line 373, in cached_file
    raise EnvironmentError(
OSError: checkpoints/longva7b-llavanextsub100k-qwen2-rev does not appear to have a file named config.json. Checkout 'https://huggingface.co/checkpoints/longva7b-llavanextsub100k-qwen2-rev/tree/None' for available files.
